---
title: "Введение в базы данных"
output: html_document
---


## Задача

Вы работаете в онлайн-магазине. У вас есть данные, содержащий три таблицы: покупателей (users), каталог товаров (inventory) и заказы (orders). Связать таблицы между собой можно по идентификаторам пользователя user_id и товара inventory_id.

```{r}
library(readr)
orders <- read_csv('~/shared/minor3_2019/1-SQL/1-practice-IntroDB/orders.csv')
inventory <- read_csv('~/shared/minor3_2019/1-SQL/1-practice-IntroDB/inventory.csv')
users <- read_csv('~/shared/minor3_2019/1-SQL/1-practice-IntroDB/users.csv')
```
```{r}
library(dplyr)
library(ggplot2)
```


Посмотрим на возможные задачи:

1. Сколько у нас всего товаров в каталоге? 
```{r}

```

2. Как распределены клиенты по полу и возрасту?
```{r}

```

3. Найдите самый популярный товар (который заказывали чаще всего)
```{r}

```

4. Люди какой профессии больше всего заказывают книги?
```{r}

```

Обсуждение:
* какие таблицы нам нужны для ответа на каждый из вопросов?
* как мы соединяем таблицы, если используем, например, две (или три) из них
* зачем нам вообще разделение на таблицы, почему бы не хранить все в одной

Решать такие (и более сложные) задачи мы уже умеем. Что же нового?

А теперь представим следующую ситуацию:
1. К нам пришел новый клиент и купил книгу Coming Home
2. В нашей внутренней системе добавилась новая запись в таблице users
3. В нашей внутренней системе добавилась новая запись в таблице orders
4. А потом пришли еще 20 клиентов и для них повторились пункты 2-3
5. Если мы хотим повторить анализ, мы опять скачиваем файлы из системы, загружаем их в R и перезапускаем код

Плюсы:
* у нас есть код, в нем не нужно ничего менять, только перезапустить (воспроизводимость!)

Минусы:
* нужно не забыть обновить файлы
* мы каждый раз храним в памяти все датасеты, что может занимать много места и времени на обработку
* во внутренних системах данные обычно не хранятся в файлах формата csv, т.е. нужно преобразовывать

Для хранения данных в больших (и не очень) системах используют обычно более удобные и универсальные инструменты, которые называются СУБД (системы управления базами данных) -- в них обычно есть средства для оптимального хранения, поиска, организации данных. Они бывают разных типов, один из самых популярных -- так называемые реляционные базы данных (по сути -- те самые таблицы, с которыми мы привыкли работать), т.е. данные имеют четкую структуру. 

Есть принятые правила того, как должны быть организованы данные в базе
* не должно быть дублирующей информации
* не должно быть значений, которые можно вычислить по другим (например, колонки сумма заказа, если там же есть данные про цену и количество) -- т.к. если мы произведем изменения в одной из колонок, но не поменяем во второй, то получим противоречие в данных
* именно поэтому данные разделяют на логические блоки -- таблицы (соответсвующие каким-то сущностям, например, клиенты и их характеристики, товары и их характеристики, заказы)

**Пример**
Вы решили сделать каталог своей домашней библиотеки
* какие сущности можно выделить
* какие характеристики вы бы указали
* как бы вы организовали это в таблицы

Разовьем задачу. Пусть это не ваша библиотека, а публичная. Какие еще характеристики/таблицы вы бы добавили?

### Доступ к данным
После того, как мы спланировали структуру (или если в системе уже есть какая-то база, спроектированная кем-то раньше), нам нужно получить доступ к данным. Можно делать это так, как мы начали -- скачивать данные в виде файлов, но это неудобно, особенно, если данные объемные. Чаще всего, нам все равно нужно иметь дело только с частью данных для каждого вопроса.

Для получения доступа к данным придумали специальный язык SQL (structured query language — «язык структурированных запросов»). Он достаточно простой и по логике похож на то, что мы делали в dplyr -- выбрать данные из таблицы по условию. Про сам язык подробнее поговорим следующий раз, а сегодня только пара примеров.

Основное отличие при работе с базами данных, а не с загруженными файлами -- мы не загружаем датасет в память целиком, а получаем доступ только к тем данным, что нам нужны в данный момент (поэтому, кстати, важно не присоединять лишние таблицы, если они не нужны для ответа на поставленный вопрос).

Сделаем симуляцию удаленной базы данных (да, в нашем случае эта база все равно хранится в памяти, но пример легко обобщается на удаленную базу просто заменой информации о соединении (connection))

```{r}
con <- DBI::dbConnect(RSQLite::SQLite(), ":memory:")
copy_to(con, orders)
```

Можно посмотреть на данные -- 
```{r}
ord <- tbl(con, "orders")
ord
str(ord)
```

И этот объект занимает гораздо меньше места, чем исходная таблица

Напишем запрос (сегодня -- средствами dbplyr <https://dbplyr.tidyverse.org/index.html>, т.е. так, как мы привыкли)
```{r}
library(dbplyr)
summary <- ord %>% 
  group_by(user_id) %>% 
  summarise(total = sum(quantity, na.rm = T)) %>% 
  arrange(desc(total))
```

Посмотрим на внутренную структру
```{r}
# see query
summary %>% show_query()
```

И на результат
```{r}
# execute query and retrieve results
summary %>% collect()
```
